

\subsection{Configuration Model}
We look at one extreme where we randomly sample a fraction of nodes from a network and organise them into a coalition. Given a network generated by the configuration model, we want to calculate the average number of edges pointing to $C$ nodes if they are randomly sampled. Suppose we take away the fraction $1-c$ of nodes not in $C$. Then the degree distribution in the remaining set of nodes $C$ is
\begin{equation}
p_c'(j,k) = \sum_{J, K} p(J,K) {J \choose j} c^j(1-c)^{J-j} {K \choose k} c^k(1-c)^{K-k}.
\end{equation}
The expected total in-degree of $C$ before percolation is $Nc \times \sum_{j,k} j P(j,k) = Nc\langle j \rangle$. After percolation, the expected in-degree is
\begin{align}
\sum_{j,k} j\ p_c'(j,k) &= \sum_j \sum_{J, K} p(J,K) {J \choose j} j c^j(1-c)^{J-j} {K \choose k} c^k(1-c)^{K-k} \\
&= \sum_{J} P(J) Jc \\
&= c\langle j\rangle.
\end{align}
Hence after percolation the total number of edges remaining is $Nc^2\expval{j}$. Therefore the number of in-edges from the nodes outside the coalition is $\eta = Nc\langle j \rangle - Nc^2\langle j \rangle = Nc(1-c) \langle j \rangle$. The maximum is $\eta (1/2) = N\expval{j}/4$: the in-edges from nodes outside the coalition constitute a quarter of all edges; another quarter goes in the other direction, out of the coalition, and the remaining half are edges within the two groups.

\subsubsection{Non-uniform sampling of coalition}

Suppose now $c = c(j,k)$. For a non-trivial sampling, the degree distribution of the coalition embedded in the pre-percolation network is
\begin{equation}
p_c(j,k) = \frac{c(j,k)p(j,k)}{c}.
\end{equation}
Thus prior to percolation, the average in-degree in the coalition is
\begin{equation}
\frac{\sum_{j,k} j p(j,k) c(j,k)}{\sum_{j,k} p(j,k) c(j,k)} = \frac{\expval{jc}}{c}.
\end{equation}
So the total number of in-edges in the coalition prior to percolation is
\begin{equation}
Nc \frac{\expval{jc}}{c} = N\expval{jc}.
\end{equation}
Now we percolate the network such that only nodes in the coalition remain, where each node with i/o-degree $(j,k)$ has a survival probability of $c(j,k)$. Consider in-an edge pointing to a surviving node. The edge could only survive if the parent of the edge is also a coalition node. The probability that the parent node is a node with out-degree $k'$ is $k'p(j',k')/\expval{k}$, and the probability that such a node is also in the coalition is $k'p(j',k')/\expval{k} c(j',k')$. Thus the probability that the in or out edge survives percolation is
\begin{align}
\Pr(\text{in-edge survives}) &= \sum_{j',k'} \frac{k'p(j',k')}{\expval{k}} c(j',k') = \frac{\expval{ck}}{\expval{k}} \\
\Pr(\text{out-edge survives}) &= \sum_{j',k'} \frac{j'p(j',k')}{\expval{j}} c(j',k') = \frac{\expval{cj}}{\expval{j}}
\end{align}
(N.B. $\expval{cj} \neq \expval{ck}$!) Thus in calculating the average in-degree of the coalition after percolation we replace $c$ in the case of uniform percolation with $\expval{ck}/\expval{k}$ or $\expval{cj}/\expval{j}$ in appropriate places, and also update the i/o-degree distribution of the coalition embedded in the original netwokr $p(j,k)$ to $p_c(j,k)$, we now get
\begin{equation}
\sum_{j,k} j p_c'(j,k) = \frac{\expval{jc}\expval{kc}}{c\expval{k}}.
\end{equation}
Thus the total number of in-edges in the coalition surviving percolation is
\begin{equation}
Nc \frac{\expval{jc}\expval{kc}}{c\expval{k}} = N\frac{\expval{jc}\expval{kc}}{\expval{k}}.
\end{equation}
So the total number of in-edges pointing to the coalition from outside the coaltion is
\begin{equation}
 N\expval{jc} - N\frac{\expval{jc}\expval{kc}}{\expval{k}} = N\expval{jc}\qty(1-\frac{\expval{kc}}{\expval{k}}).
\end{equation}

We can ask another question; given a subset of nodes, how many nodes are downstream of its influence? If we follow an in-edge to its parent node, the i/o degree distribution of its parent is $\frac{k p(j,k)}{\expval{k}}$. Thus for a chosen node, the probability that its first in-edge is parented by a node with i/o-degree $(j_1, k_1)$ is $k_1p(j_1, k_1)/\expval{k}$; since each in-edge independently chooses its parent, the probability that the node has parent nodes of i/o-degrees $\qty((j_1, k_1), \ldots, (j_{j-1}, k_{j-1}))$ (labelled by some arbitrary indexing of edges) is
\begin{equation}
\Pr(\qty(j_e, k_e)_{e=1}^{j} \ \lvert \ j,k) = \prod_{e=1}^j\frac{k_e}{\expval{k}} p(j_e, k_e).
\end{equation}
Thus the probability that such nodes have either seed or coalition parents is
\begin{equation}
\Pr(\qty(j_e, k_e)_{e=1}^{j},\ Q\cup C \to \iota \ \lvert \ j,k) = \prod_{e=1}^j\frac{k_e}{\expval{k}} p(j_e, k_e)r(j_e, k_e).
\end{equation}
Summing over all degree configurations, and observing that sum of products = product of sums
\begin{align}
\Pr(Q\cup C \to \iota \ \lvert \ j,k) &= \prod_{e=1}^j\qty(\sum_{k_e,j_e})\prod_{e=1}^j\frac{k_e}{\expval{k}} p(j_e, k_e)r(j_e, k_e) \\
&= \qty(\sum_{k',j'}\frac{k'}{\expval{k}} p(j', k')r(j', k'))^j = \qty(\frac{\expval{rk}}{\expval{k}})^j
\end{align}

If we define the \emph{ideal} coalition such that
\begin{equation}
\iota \in C \qq{iff} Q \cup C \to \iota,
\end{equation}
then
\begin{align}
c(j,k) &= \Pr(\iota \in C \ \lvert \ d(\iota) = (j,k), Q)\\
 &=  \Pr(Q \cup C \to \iota \ \lvert \ d(\iota) = (j,k), Q) \\
 &= \qty(\sum_{k',j'}\frac{k'}{\expval{k}} p(j', k')r(j', k'))^j = \qty(\frac{\expval{kr}}{\expval{k}})^j.
\end{align}
We observe that $\frac{\expval{kr}}{\expval{k}}$ is nothing more than a constant (given some choice of $q$ and $c$), and thus $c(j,k) = c(j)$ is independent of $k$, i.e. probability of a node with i/o-degrees $(j,k)$ is in the coalition is independent of the node's out degree. If we let $c(j=1) = \gamma$, where $1 \geq \gamma > 0$,
\begin{equation}
c(j) = \gamma^j \quad \forall j = 1,2, \ldots.
\end{equation}
N.B. $c(0) = 0$. Furthermore if we assume that $Q$ was a random sample of the graph, where a node with i/o degrees $(j,k)$ is sampled with probability $q(j,k)$, then
\begin{equation}
r(j,k) = c(j) + q(j,k) - c(j)q(j,k).
\end{equation}
Then we can solve for $c(j)$ from a self-consistency solution:
\begin{align}
\gamma &= \sum_{k,j}\frac{k}{\expval{k}} p(j, k)\qty(q(j,k) + c(j)\qty(1-q(j,k)))\\
&= \frac{\expval{qk}}{\expval{k}} + \sum_{j=0}c(j)\sum_{k=1}\frac{k}{\expval{k}} p(j, k)\qty(1-q(j,k)) \\
&= \frac{\expval{qk}}{\expval{k}} + \sum_{j=1}\gamma^j\sum_{k=1}\frac{k}{\expval{k}} p(j, k)\qty(1-q(j,k))
\end{align}
If we have $q(j,k) = q$ and let $s(j) = \sum_{k=1}\frac{k}{\expval{k}} p(j, k)$,
\begin{align}
\gamma &= q + \qty(1-q) \sum_{j=1}\gamma^{j}s(j)\ ; \qand \\
q &= \gamma \qty(\frac{1-\sum_{j=1} \gamma^{j-1}s(j)}{1-\sum_{j=1} \gamma^js(j)})
\end{align}
We notice that there is are obvious trivial solutions $(\gamma, q) = 0$ and $\gamma(q=1) = 1$, while $q$ is undefined for $\gamma = 1$ and $s(0) = 0$ (where $p(j=0, k \neq 0)=0$). This is sign of \textbf{critical behaviour}. If $s(0) = 0$, performing an asymptotic expansion $\gamma = 1-\epsilon$, we find that $q$ becomes undefined if
\begin{equation}
q > 1 - \frac{\expval{k}}{\expval{jk}} = q_c.
\end{equation}
In other words, if we have more than $Nq_c$ seeds node $Q$, the size of the set of nodes $C$ that is downstream of $Q$ or $C$ is the whole network. This is automatically satisfied if $\expval{kj} = \expval{k}$, loosely meaning that nodes on average have one in-edge and one out-edge i.e. the network is very close to a chain. In addition, this critical value coincides with with the threshold percolation value for the existence of a \textbf{giant connected component} after removing a fraction $q$ of nodes from the network.
\subsection{Separable Dependencies}
Suppose the dependency layer consists of $M$ disconnected cliques of size $n$, each clique corresponding to a task that the needs to be fulfilled.

Suppose we have $N = nM$ agents divided into $M$ coalitions of size $n$. In the ideal situation, each coalition is assigned to one task. Agents within the coalition can coordinate their actions between themselves to optimise the clique the coalition occupies.

If we build a bipartite graph consisting of coalition nodes and task (clique) nodes there is a one-to-one correspondence between coalitions and tasks. The edges are weighted according to the number of agents assigned from a coalition to a task: in the perfect matching case every edge has weight $n$.

However suppose there is a mismatch between coalitions and cliques: How bad would it be? We start with the perfectly matched state and consider two coalitions $A$ and $B$ sitting on two distinct task cliques $\alpha$ and $\beta$, where $\alpha$ is only occupied by $A$ agents and $\beta$ is occupied by only $B$ agents. We perturb the system by swapping $m$ agents from $A$ and $B$ across $\alpha$ and $\beta$ cliques, to the effect that the $\alpha$ clique would be occupied by $n-m$ $A$ agents and $m$ $B$ agents, and vice versa for the $\beta$ clique.

In our bipartite graph of coalitions and tasks, there is an extra edge of weight $w_{A\beta} = m$ between $A$ and $\beta$ and another between $B$ and $\alpha$. The weights of edges between $A$ and $\alpha$ and $B$ and $\beta$ respectively are weakened to $w_{A\alpha} = w_{B\beta} = n-m$ due to the sharing.

Now the $A$ coalition is no longer independent and the outcomes of their actions are dependent on the actions of $B$ nodes and vice versa; we can say that they have become entangled. The $A$ agents that remain on $\alpha$ must accept the influence of the $m$ $B$ agents that are participating in the $\alpha$ task, and their collective decision making is also influenced by the $m$ $A$ agents participating in task $\beta$, influenced by $n-m$ $B$ agents that had remained on $\beta$. Thus $A$ is subjected to the influence of $n$ agents from coalition $B$ (and vice versa), so long as $m >0$.

We quantify the degree of entanglement $\omega_{AB}$ between coalitions $A$ and $B$ to be the number of $B$ agents that influence the utility of $A$'s actions. We alert the reader that $\omega_{AB} \neq \omega_{BA}$. Furthermore we draw attention to the fact that $\omega_{AB}$ is not the number of edges between $A$ and $B$ nodes, since one agent from $A$ can influence multiple $B$ agents but there is only one external $A$ agent influencing the entire $B$ coalition.

We examine the relationship between coalition nodes by collapsing the bipartite graph and remove the clique nodes. We place an edge between two coalition nodes $A$ and $B$ if they have edges pointing to the same task node in the bipartite graph (i.e. agents from both coalitions participate in the same task).

There are two ways that two coalitions can share in a task and induce an edge between them in the collapsed coalition graph. The first one we call a `direct swap', where $\alpha$ and $\beta$ tasks swap $A$ and $B$ agents, where $A$ and $B$ are $\alpha$ and $\beta$'s `perfect matching' coalitions; the second we call an `intermediary swap',  where $A$ and $B$ independently perform direct swaps of agents with another coalition $C$ and participate in task $\gamma$. Since $A$ and $B$ participate in the same task $\gamma$, we place an edge between $A$ and $B$ when we collapse the bipartite graph.

We weight the edges on the collapsed graph with $\omega_{AB}$, the number of $B$ nodes influencing coalition $A$. Since $\omega_{AB} \neq \omega_{BA}$, we associate two weights to the edge. Denoting $\mathcal{B}$ as the \emph{unweighted} adjacency matrix of the bipartite graph $\mathcal{B}_{A\beta} = \Theta(\omega_{A\beta})$ ($\Theta(x)$ being the Heaviside step function), we compute $\omega_{AB}$ using the equation
\begin{equation}\label{eq:omegaab}
\omega_{AB} = \sum_{\gamma} \mathcal{B}_{A\gamma}w_{B\gamma} = \qty(\mathcal{B}w^T)_{AB}.
\end{equation}
We observe that
\begin{equation}
\omega_{BA} = \sum_{\gamma} \mathcal{B}_{B\gamma}w_{A\gamma} = \qty(w\mathcal{B}^T)_{AB}.
\end{equation}

we make an additional simplifying assumption, that $w_{A\alpha} \sim \text{Po}(n-(M-1)\lambda)$. After plugging this into mathematica we get
\begin{equation}
G(z) = e^{\lambda -\lambda  M-n} \left(\left(e^{\lambda }-1\right) e^{\lambda  (z-1)}+1\right)^{M-2} \left(e^{\lambda  (M-1)}-e^{\lambda  (M+z-2)}+e^{n+\lambda  (z-1)}\right) \left(\left(e^{\lambda }-1\right)
   e^{(z-1) (\lambda -\lambda  M+n)}+1\right).
\end{equation}

The probability that two coalitions are not connected is
\begin{equation}
\Pr(\omega_{AB} = 0) = G(0) = \frac{\left(2-e^{-\lambda }\right)^M e^{-\lambda  (M-2)-2 n} \left(-e^{\lambda  (M-1)}+e^{\lambda  M}+e^n\right)^2}{\left(1-2 e^{\lambda }\right)^2}.
\end{equation}

And the mean influence strength of $B$ on $A$ is
\begin{equation}
\expval{\omega_{AB}} = G'(1)= e^{-(n+\lambda)} \left(-\lambda  e^{\lambda  M}+n e^{\lambda +n}+e^n (\lambda -n)\right)
\end{equation}

[INSERT GRAPHS]


\section{Dynamic Model of Agent Interactions}
\subsection{Agents and Cooperation}
Let there be $N$ agents indexed by $i \in \mathcal{I}$ working together on a project. Each agent has a (finite) set of actions $A_i$ which they could employ to modify particular contents of the project. The state of the entire project sits in the product space of all actions $A = A_1 \times \ldots \times A_N$.  We associate to each agent a utility function, $u : \mathcal{I} \times A \to \mathbb{R}$, which we can interpret as the agent's happiness at a given state.

While the objective of an individual agent is to selfishly maximise their own utility, the project only goes forward when all of the agents are `sufficiently happy': If any one agent is too unhappy, the project cannot proceed.

Firstly, we define the \textbf{collective optimisation problem} (the Co-Op) where where all agents sit together, \emph{pool} their information - i.e. their utility functions - and \emph{altruistically} maximise their \textbf{collective benefit function} $U(a) = \min_{i \in \mathcal{I}} u_i(a)$, so that no agent is `left behind' in the name of `progress':

\begin{equation}
\max_{a \in A} \min_{i \in \mathcal{I}} u_i(a)  = U^\ast
\end{equation}

The optimum (optima) of this problem is $U^\ast = u_{i^\ast}(a^\ast)$. There are good reasons to choose this philosophy: quite often there is no actual global utility function to optimise over agents. Multi-agent algorithms often optimise the sum of local utility functions which is an arbitrary choice. A bad reason to adopt this philosophy is when there is a sensible definition of global utility function.

Suppose each agent acts selfishly and wants to push the project towards a state that maximises their own utility $\max_{a \in A} u_i(a)$. Then if all agents optimising selfishly can all do better then $U^\ast$, then they would not end up in the state $a^\ast$ that optimises Co-Op. In other words, the condition that selfish agents fail to `Co-Op' is
\begin{equation}
\max_{a \in A} \min_{i \in \mathcal{I}} u_i(a) < \min_{i \in \mathcal{I}} \max_{a \in A} u_i(a)
\end{equation}
However there is this famous inequality, well known in game theory and optimisation circles:
$$ \max_{a \in A} \min_{i \in \mathcal{I}} u_i(a)   \leq \min_{i \in \mathcal{I}} \max_{a \in A} u_i(a)$$ with stringent conditions on $\mathcal{I}$, $A$ and $u$ for equality to hold. So generically, selfish actions cannot lead to the  `Co-op' communist utopia.

However, the assumption that a selfish agent can maximise over all states $A$ is unrealistic - it can only control the set of actions available to itself. In addition, it is computationally inefficient for a single for a single player to pre-compute $u$ for all states of the system, especially for complex games such as chess, and it is only feasible for the agent to evaluate $u$ \emph{during} the game as it is presented with the actions of other agents.


\subsection{The Dependency Network}
We construct the dependency network with the following procedure. if agent $i$ influences agent $j$ - and we assume influence is a reflexive,i.e. then $j$ influences $i$ - then we put an edge between every agent who influences each other.

We will consider two types of dependency networks. One case to consider is the random network configuration model in the large $N$ limit, with node distributions . In this limit the network is locally tree like i.e. there is no clustering. Such graphs are characterised by the existence of hubs. Another case is the high clustering limit. For example, we consider a dependency network consisting of disjoint $k>1$-cliques, or $k-$cliques with intersecting faces of dimension much less than $k$.

\subsection{Social Structure and Coalitions}
Agents need a social structure to communicate intention. In an organisation people usually meet as a group to discuss ideas. We imagine there is a fixed number of meeting rooms and at each time step each and every agent goes into a meeting room. In each meeting room the agents present then form what we call a \textbf{coalition}.

How do coalitions deliberate and take action? Suppose the agents were given some state initial state $a_0 \in A$. As the agents updates their actions it evolves in discrete time steps $a_0 \to a_1 \to \cdots \to a_T$.  Let $C \subseteq \mathcal{I}$ be a subset of agents and denote $A(C)$ to be the actions available to agents in $C$. At time $t$ the agents in $C$ come together as a coalition to solve the the problem
\begin{equation}
a_t = \arg\max_{a \in A(C)} \min_{i \in C} u_i(a \lvert a_{t-1})= \mathcal{C}\ a_{t-1}.
\end{equation}
We call $\mathcal{C}: A \to A$ a \textbf{coalition operator}. Members of a coalition can:
\begin{itemize}
 \item Coordinate their actions (in max operation).
 \item Share information about their utility function (in min operation).
 \item The state space they could explore is restricted by its immediate predecessor $a_{t-1}$.
 \item The coalition updates the system to a new state where the worse off member of the coalition has a greater utility.
\end{itemize}
Since every agent is in a coalition at any time, the set of actions is updated in parallel by every coalition at time $t$. We want the partition of agents in each time step to put agents that depend on each other into the same coalition, i.e. it is optimal if all the dependencies can be resolved in the same discussion:
\begin{equation}
\arg\max_{a \in A(C)} \min_{i \in C} u_i(a \lvert a_{t-1})= \arg\max_{a \in A(C)} \min_{i \in C} u_i(a).
\end{equation}
We note that each coalition is unaware of the actions taken by the other coalitions that happen simultaneously.

After the coalitions finish their deliberations they leave the meeting rooms and form new coalitions in other meeting rooms. During deliberation agents in a coalition learn about the dependency relationships between agents in the coalition and they organise themselves into connected components. When they break apart, each connected component will travel together to some other meeting room and form coalitions with other agents.

This process will terminate when all the nodes have discovered all of its partners. Thus there are two dynamics happening simultaneously: one is the update of actions, the other is the process of finding connections between agents.

\subsection{The Coordination Game}
In a coordination game, nodes can choose to coordinate ($a = 1$) or not ($a = 0$); if all neighbours on the dependency graph decides to coordinate, then it is beneficial for the node to choose to coordinate ($u(1\ \lvert\ 1,..,1) >0$), otherwise if the node chooses 1 and some neighbour refuses to coordinate, there is a penalty for the node ($u(1 \ \lvert 1, 0, ..., 1)<0$). If the node refuses to coordinate, it always has a neutral payoff ($u(0 \ \lvert \ ...) =0$).
The global objective is for everyone to coordinate.

How does the coordination game operate within the framework of a coalition game? Consider a coalition $C$ of nodes at time $t$ and the connected components in $C$. Agents in each of the connected components in the coalition would decide to coordinate if either
\begin{enumerate}
\item the connected component contained in $C$ is an entire connected component in the graph; or
\item the agents that are not contained in the connected component  has agreed to coordinate in the previous time step.
\end{enumerate}

We build in an extra mechanism to facilitate coordination. If a majority of the nodes in the coalition decide to coordinate, then the rest of the nodes who do not coordinate will temporarily try to coordinate. In the next time step, all other nodes will read such nodes as having decided to coordinate. However, if in the next time step the nodes that temporarily coordinate do not meet the conditions above, they will decide not to coordinate.
